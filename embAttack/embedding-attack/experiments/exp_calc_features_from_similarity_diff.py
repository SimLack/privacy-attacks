#!/usr/bin/env python

from features import create_features as cf, feature_type as ft
import memory_access as sl
import graphs.graph_class as gc
import multiprocessing
import functools
import config
import features.diff_type as dt
import pandas as pd
import features.diff_matix_most_similiar_embeddings as dmm
import experiments.exp_utils as exp_utils
import time


def compute_training_features_for_one_node_pool(save_info: sl.MemoryAccess, graph: gc.Graph,
                                                num_of_bins: int, feature_type: ft.FeatureType,
                                                nodes_to_train_on: {}, o_dm_list: [pd.DataFrame],
                                                node_to_predict: int):
    '''
    Compute features using most similiar embeddings. Thereby it only uses multiple embeddings for the second graph
    :param save_info:
    :param graph:
    :param num_of_bins:
    :param feature_type:
    :param nodes_to_train_on:
    :param node_to_predict:
    :return:
    '''

    num_iter = save_info.get_num_iterations()

    quantity_dict = {dt.DiffType.MOST_SIMILAR_EMBS_DIFF: [1, num_iter, 1],
                     dt.DiffType.MOST_SIMILAR_EMBS_DIFF_ALL_EMBS: [num_iter, num_iter, num_iter],
                     dt.DiffType.MOST_SIMILAR_EMBS_DIFF_ONE_INIT: [1, num_iter, num_iter],
                     dt.DiffType.MOST_SIMILAR_EMBS_DIFF_ONE_INIT_CONTINUE: [1, num_iter, num_iter]}

    quantity = quantity_dict[save_info.get_diff_type()]

    used_emb = save_info.get_diff_type().get_iter()

    # compute attack features
    diff, min_r_dm = dmm.compute_diff_matrix(removed_nodes=[node_to_predict], save_info=save_info,
                                             quantity_first=quantity[0], quantity_second=quantity[1],
                                             used_emb=used_emb, o_dm_list=o_dm_list)
    cf.create_features(diff=diff, removed_nodes=[node_to_predict], original_graph=graph, num_of_bins=num_of_bins,
                       feature_type=feature_type, save_info=save_info)

    # compute training features
    if save_info.is_diff_type(dt.DiffType.MOST_SIMILAR_EMBS_DIFF_ONE_INIT_CONTINUE):
        # this diff type uses the dm of G' used for diff(G,G') for diff(G',G'')
        o_dm_list_t = [min_r_dm]
        quantity[1] = 1
    else:
        o_dm_list_t = None

    g_prime = graph.delete_node(removed_node=node_to_predict)
    for tr_node in nodes_to_train_on[node_to_predict]:
        removed_nodes = [node_to_predict, tr_node]

        diff, i = dmm.compute_diff_matrix(removed_nodes=removed_nodes, save_info=save_info,
                                          quantity_first=quantity[1], quantity_second=quantity[2], used_emb=used_emb,
                                          o_dm_list=o_dm_list_t)
        cf.create_features(diff=diff, removed_nodes=removed_nodes, original_graph=g_prime, num_of_bins=num_of_bins,
                           feature_type=feature_type, save_info=save_info)


def compute_training_features_from_similarity_diff(save_info: sl.MemoryAccess, graph: gc.Graph,
                                                   num_of_bins: int, feature_type: ft.FeatureType = None,
                                                   p_nodes: [int] = None, t_nodes: {} = None):
    """
    Computes training and test features generated from difference matrix generated by similarity diff matrix
    :param save_info: memory access obj
    :param graph: graph the embedding is trained on (used to access nodes lists)
    :param num_of_bins: number of bins the feature vector should use
    :param feature_type: type of the features to compute
    :param p_nodes: nodes that are used as test_cases.
            If None nodes are determined by available files in the file system
    :param t_nodes: nodes that are used for training in each test case. Dict from the node_to_predict to [int]
            containin the training nodes for that tested node.
            If None
    """
    print('start sequence part')
    start_squence = time.time()

    num_features = len(p_nodes)

    p_nodes, t_nodes = exp_utils.filter_by_already_trained_nodes(
        p_node_list=p_nodes, t_node_dict=t_nodes, graph=graph,
        save_info=save_info, feature_type=feature_type, num_bins=num_of_bins)

    if len(p_nodes) > 0:
        if save_info.get_diff_type().has_iteration():
            assert (save_info.get_diff_type().has_one_init_graph())
            iteration = save_info.get_diff_type().get_iter()
            o_dm_list = dmm.load_dms(removed_nodes=[], save_info=save_info, num_iterations=1,
                                     use_specific_iter=iteration)
        else:
            o_dm_list = dmm.load_dms(removed_nodes=[], save_info=save_info,
                                     num_iterations=save_info.get_num_iterations())

        func_p = functools.partial(compute_training_features_for_one_node_pool,
                                   save_info, graph,
                                   num_of_bins, feature_type,
                                   t_nodes, list(o_dm_list))

        end_sequence = time.time()
        print(f'Sequence duration {end_sequence - start_squence}')
        start_pool = time.time()
        with multiprocessing.Pool(min(config.NUM_CORES, len(p_nodes))) as pool:
            for res in pool.imap(func_p, p_nodes):
                pass
        end_pool = time.time()
        print(f'Pool duration {end_pool - start_pool}')

        '''
        for i in list_nodes_to_predict:
            func_p(i)
        '''

    else:
        if num_features == 0:
            print("no embeddings found to create training features for")
        else:
            print(f"All features are already trained. Number of training features {num_features}")
